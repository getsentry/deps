#!/usr/bin/env python3
import csv
import json
from collections import defaultdict

eco_map = {
    'js': 'JavaScript',
    'py': 'Python',
    'rs': 'Rust',
}

github = json.load(open('github.json'))
counts = {
    'ecos': defaultdict(int),
    'orgs': defaultdict(lambda: defaultdict(int))
}
urls = dict()
data = defaultdict(lambda: defaultdict(list))
for org, url, repo, stars, eco in csv.reader(open('deps.csv')):
    stars = int(stars)
    occurrences = github[eco][org][repo]
    eco = eco_map.get(eco, eco)

    counts['ecos'][eco] += 1
    counts['orgs'][eco][org] += 1
    urls[org] = url
    data[eco][org].append((stars, occurrences, repo))

out = open('links.html', 'w+')
def p(*a, **kw):
    print(*a, **kw, file=out)

p('<html><head><link rel="stylesheet" href="links.css"></head><body><div class="ecos">')
for n, eco in reversed(sorted([(v,k) for k,v in counts['ecos'].items()])):
    p(f'<h1 class="pad">{eco} ({n})</h1>')
    p(f'<table class="orgs">')
    for n, org in reversed(sorted([(v,k) for k,v in counts['orgs'][eco].items()])):
        url = urls[org]
        p(f'<tr class="org">')
        p(f'<td class="pad"><a href="{url}" target="_blank">{org}</a> ({n})</td>')
        p(f'<td class="scroll"><table class="repos">')
        for i, (stars, occurrences, repo) in enumerate(reversed(sorted(data[eco][org]))):
            p(f'<tr>')
            p(f'<td class="pad"><a href="https://github.com/{org}/{repo}">{repo}</a></td>')
            p(f'<td class="pad num">{stars}</td>')
            p(f'<td class="pad num">{occurrences}</td>')
            p(f'</tr>')
            if i == 4:
                if i+i < n:
                    p(f'<tr>')
                    p(f'<td class="pad">...</td>')
                    p(f'<td class="pad num">...</td>')
                    p(f'<td class="pad num">...</td>')
                    p(f'</tr>')
                break
        p(f'</table></td></tr>')
    p(f'</table>')
p('</div></body></html>')
